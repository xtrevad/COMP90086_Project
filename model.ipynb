{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb6d8fb-64ea-4fc0-b14d-3758ae3c5919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training dataset statistics...\n",
      "Training dataset mean: tensor([0.4675, 0.4409, 0.4062])\n",
      "Training dataset std: tensor([0.2719, 0.2284, 0.1912])\n",
      "Training...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd87b1a700484bb89261d32a1c9ffed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 355\u001b[0m\n\u001b[0;32m    295\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m# Path to the CSV file containing training data\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_csv\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./COMP90086_2024_Project_train/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions_save_path\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    352\u001b[0m }\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 264\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 264\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mearly_stopping_patience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_save_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete. Model saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 107\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience, device)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[0;32m    106\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 107\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[0;32m    110\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[5], line 145\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(model, data_loader, criterion, optimizer, device, is_training)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Create progress bar\u001b[39;00m\n\u001b[0;32m    143\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(data_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_training \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 145\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[5], line 75\u001b[0m, in \u001b[0;36mStabilityDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     72\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size), Image\u001b[38;5;241m.\u001b[39mBILINEAR)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 75\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, torch\u001b[38;5;241m.\u001b[39mtensor(stability_class, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bensa\\Documents\\Git\\COMP90086_Project\\.venv\\Lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[0;32m    167\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[1;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import EfficientNet_V2_S_Weights\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import platform\n",
    "import multiprocessing\n",
    "\n",
    "# Custom dataset class for handling stability data\n",
    "class StabilityDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, augment=False, image_size=224, zoom_proportion=0.15):\n",
    "        self.stability_data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.image_size = image_size\n",
    "        self.zoom_proportion = zoom_proportion\n",
    "        self.augmented_indices = self._create_augmented_indices() if augment else None\n",
    "\n",
    "    # Create indices for augmented data\n",
    "    def _create_augmented_indices(self):\n",
    "        base_indices = list(range(len(self.stability_data)))\n",
    "        flipped_indices = [idx + len(self.stability_data) for idx in base_indices]\n",
    "        zoomed_indices = [idx + 2 * len(self.stability_data) for idx in base_indices]\n",
    "        zoomed_flipped_indices = [idx + 3 * len(self.stability_data) for idx in base_indices]\n",
    "        return base_indices + flipped_indices + zoomed_indices + zoomed_flipped_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stability_data) * 4 if self.augment else len(self.stability_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment:\n",
    "            original_idx = idx % len(self.stability_data)\n",
    "            augmentation = idx // len(self.stability_data)\n",
    "        else:\n",
    "            original_idx = idx\n",
    "            augmentation = 0\n",
    "\n",
    "        # Load image and stability class\n",
    "        img_name = str(self.stability_data.iloc[original_idx, 0])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(self.img_dir, f\"{img_name}.jpg\")\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        stability_height = self.stability_data.iloc[original_idx, -1]\n",
    "        stability_class = int(stability_height) - 1\n",
    "\n",
    "        # Apply augmentations if enabled\n",
    "        if self.augment:\n",
    "            if augmentation in [1, 3]:  # Flip\n",
    "                image = image.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "            if augmentation in [2, 3]:  # Zoom\n",
    "                width, height = image.size\n",
    "                crop_size = int(min(width, height) * (1 - self.zoom_proportion))\n",
    "                left = (width - crop_size) // 2\n",
    "                top = (height - crop_size) // 2\n",
    "                right = left + crop_size\n",
    "                bottom = top + crop_size\n",
    "                image = image.crop((left, top, right, bottom))\n",
    "\n",
    "        # Resize the image to ensure consistent size\n",
    "        image = image.resize((self.image_size, self.image_size), Image.BILINEAR)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(stability_class, dtype=torch.long)\n",
    "\n",
    "# Neural network model for stability prediction\n",
    "class StabilityPredictor(nn.Module):\n",
    "    def __init__(self, num_classes=6, dropout_rate=0.3):\n",
    "        super(StabilityPredictor, self).__init__()\n",
    "        weights = EfficientNet_V2_S_Weights.DEFAULT\n",
    "        self.efficientnet = models.efficientnet_v2_s(weights=weights)\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate, inplace=True),\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, device, is_training=True)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer, device, is_training=False)\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 60)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "            model.load_state_dict(best_model)\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to run a single epoch (training or validation)\n",
    "def run_epoch(model, data_loader, criterion, optimizer, device, is_training=True):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\" if is_training else \"Validating\")\n",
    "\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Function to calculate dataset statistics\n",
    "def calculate_stats(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=100, num_workers=0, shuffle=False)\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "    \n",
    "    mean /= len(dataset)\n",
    "    std /= len(dataset)\n",
    "    return mean, std\n",
    "\n",
    "# Function to make predictions on the test set\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, ids in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy() + 1)  # Add 1 to convert back to 1-6 range\n",
    "            image_ids.extend(ids.numpy())  # Convert tensor to numpy array\n",
    "    return predictions, image_ids\n",
    "\n",
    "# Main function to orchestrate the training and prediction process\n",
    "def main(config):\n",
    "    # Set up device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Create full dataset without normalization and augmentation\n",
    "    full_dataset = StabilityDataset(csv_file=config['train_csv'], \n",
    "                                    img_dir=config['train_img_dir'], \n",
    "                                    transform=transforms.ToTensor(),\n",
    "                                    augment=False,\n",
    "                                    image_size=config['image_size'])\n",
    "\n",
    "    # Split dataset into train and validation\n",
    "    dataset_size = len(full_dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(config['val_ratio'] * dataset_size))\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Calculate statistics for training set only\n",
    "    train_subset = Subset(full_dataset, train_indices)\n",
    "\n",
    "    print(\"Calculating training dataset statistics...\")\n",
    "    train_mean, train_std = calculate_stats(train_subset)\n",
    "    print(f\"Training dataset mean: {train_mean}\")\n",
    "    print(f\"Training dataset std: {train_std}\")\n",
    "\n",
    "    # Create transforms for both training and validation using training set statistics\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=train_mean, std=train_std),\n",
    "    ])\n",
    "\n",
    "    # Create augmented training dataset and non-augmented validation dataset\n",
    "    train_dataset = StabilityDataset(csv_file=config['train_csv'], \n",
    "                                     img_dir=config['train_img_dir'], \n",
    "                                     transform=data_transform,\n",
    "                                     augment=config['use_augmentation'],\n",
    "                                     image_size=config['image_size'],\n",
    "                                     zoom_proportion=config['zoom_proportion'])\n",
    "    train_dataset = Subset(train_dataset, [i for i in range(len(train_dataset)) if i % len(full_dataset) in train_indices])\n",
    "\n",
    "    val_dataset = StabilityDataset(csv_file=config['train_csv'], \n",
    "                                   img_dir=config['train_img_dir'], \n",
    "                                   transform=data_transform,\n",
    "                                   augment=False,\n",
    "                                   image_size=config['image_size'])\n",
    "    val_dataset = Subset(val_dataset, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=config['num_workers'])\n",
    "\n",
    "    # Initialize model, criterion, optimizer, and scheduler\n",
    "    model = StabilityPredictor(num_classes=config['num_classes'], dropout_rate=config['dropout_rate'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=config['lr_factor'], patience=config['lr_patience'])\n",
    "\n",
    "    # Train model\n",
    "    print('Training...')\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                        num_epochs=config['num_epochs'], patience=config['early_stopping_patience'], device=device)\n",
    "\n",
    "    torch.save(model.state_dict(), config['model_save_path'])\n",
    "    print(\"Training complete. Model saved.\")\n",
    "\n",
    "    # Prediction on test set\n",
    "    test_dataset = StabilityDataset(csv_file=config['test_csv'],\n",
    "                                    img_dir=config['test_img_dir'],\n",
    "                                    transform=data_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=config['num_workers'])\n",
    "\n",
    "    predictions, image_ids = predict(model, test_loader, device)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    with open(config['predictions_save_path'], 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['id', 'labels'])\n",
    "        for img_id, pred in zip(image_ids, predictions):\n",
    "            writer.writerow([int(img_id) + 1, int(pred)])  # Ensure both are integers\n",
    "    print(f\"Predictions saved to {config['predictions_save_path']}\")\n",
    "\n",
    "# Function to get optimal number of workers for data loading\n",
    "def get_optimal_num_workers():\n",
    "    # Windows can't do multiprocessing\n",
    "    if platform.system() == 'Windows':\n",
    "        return 0\n",
    "    else:\n",
    "        return multiprocessing.cpu_count()\n",
    "\n",
    "# Hyperparameters and configuration\n",
    "config = {\n",
    "    # Path to the CSV file containing training data\n",
    "    'train_csv': './COMP90086_2024_Project_train/train.csv',\n",
    "    \n",
    "    # Directory containing training images\n",
    "    'train_img_dir': './COMP90086_2024_Project_train/train',\n",
    "    \n",
    "    # Path to the CSV file containing test data\n",
    "    'test_csv': './COMP90086_2024_Project_test/test.csv',\n",
    "    \n",
    "    # Directory containing test images\n",
    "    'test_img_dir': './COMP90086_2024_Project_test/test',\n",
    "    \n",
    "    # Size to which all images will be resized (224x224 pixels)\n",
    "    'image_size': 224,\n",
    "    \n",
    "    # Proportion of training data to use for validation\n",
    "    'val_ratio': 0.05,\n",
    "    \n",
    "    # Whether to use data augmentation during training\n",
    "    'use_augmentation': True,\n",
    "    \n",
    "    # Proportion of zoom to apply during augmentation\n",
    "    'zoom_proportion': 0.15,\n",
    "    \n",
    "    # Number of samples per batch for training and validation\n",
    "    'batch_size': 16,\n",
    "    \n",
    "    # Number of subprocesses to use for data loading (automatically determined)\n",
    "    'num_workers': get_optimal_num_workers(),\n",
    "    \n",
    "    # Number of classes in the classification task (6 stability levels)\n",
    "    'num_classes': 6,\n",
    "    \n",
    "    # Dropout rate for regularization in the model\n",
    "    'dropout_rate': 0.3,\n",
    "    \n",
    "    # Initial learning rate for the optimizer\n",
    "    'learning_rate': 0.001,\n",
    "    \n",
    "    # Factor by which to reduce learning rate on plateau\n",
    "    'lr_factor': 0.1,\n",
    "    \n",
    "    # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    'lr_patience': 2,\n",
    "    \n",
    "    # Maximum number of training epochs\n",
    "    'num_epochs': 30,\n",
    "    \n",
    "    # Number of epochs with no improvement after which training will be stopped\n",
    "    'early_stopping_patience': 5,\n",
    "    \n",
    "    # File path where the trained model will be saved\n",
    "    'model_save_path': 'stability_predictor_efficientnetv2.pth',\n",
    "    \n",
    "    # File path where the predictions on the test set will be saved\n",
    "    'predictions_save_path': 'predictions.csv'\n",
    "}\n",
    "    \n",
    "# Run the main function\n",
    "main(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
