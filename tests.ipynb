{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0866d874-92b9-4699-9465-a4b624919beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import EfficientNet_V2_S_Weights\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b946f7e1-dfa4-46c2-96fc-0f8a65f5f2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Class 1: 1920 samples (25.00%)\n",
      "Class 2: 1920 samples (25.00%)\n",
      "Class 3: 1536 samples (20.00%)\n",
      "Class 4: 1152 samples (15.00%)\n",
      "Class 5: 768 samples (10.00%)\n",
      "Class 6: 384 samples (5.00%)\n",
      "\n",
      "Imbalance ratio: 5.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_dataset_balance(csv_file, label_column):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Count the occurrences of each class\n",
    "    class_counts = df[label_column].value_counts().sort_index()\n",
    "    \n",
    "    # Calculate the percentage of each class\n",
    "    class_percentages = 100 * class_counts / len(df)\n",
    "    \n",
    "    # Print the counts and percentages\n",
    "    print(\"Class distribution:\")\n",
    "    for class_label, count in class_counts.items():\n",
    "        percentage = class_percentages[class_label]\n",
    "        print(f\"Class {class_label}: {count} samples ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Calculate the imbalance ratio\n",
    "    imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "    print(f\"\\nImbalance ratio: {imbalance_ratio:.2f}\")\n",
    "    \n",
    "    # Visualize the class distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "    plt.title('Class Distribution in Dataset')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.show()\n",
    "\n",
    "# Usage example\n",
    "check_dataset_balance('./COMP90086_2024_Project_train/train.csv', 'stable_height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912d5531-9cdd-4d31-aafe-c04cd2b37031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StabilityDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, augment=False):\n",
    "        self.stability_data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stability_data) * (2 if self.augment else 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx // 2 if self.augment else idx\n",
    "        flip = self.augment and idx % 2 == 1\n",
    "\n",
    "        img_name = str(self.stability_data.iloc[original_idx, 0])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(self.img_dir, f\"{img_name}.jpg\")\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        stability_height = self.stability_data.iloc[original_idx, -1]\n",
    "        stability_class = int(stability_height) - 1\n",
    "\n",
    "        if flip:\n",
    "            image = image.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(stability_class, dtype=torch.long)\n",
    "\n",
    "class StabilityPredictor(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(StabilityPredictor, self).__init__()\n",
    "        weights = EfficientNet_V2_S_Weights.DEFAULT\n",
    "        self.efficientnet = models.efficientnet_v2_s(weights=weights)\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd9b6e1-0c90-4513-b67d-ecc5e8381edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset statistics...\n",
      "Processed 1000 images\n",
      "Processed 2000 images\n",
      "Processed 3000 images\n",
      "Processed 4000 images\n",
      "Processed 5000 images\n",
      "Processed 6000 images\n",
      "Processed 7000 images\n",
      "Dataset mean: tensor([0.4677, 0.4412, 0.4065])\n",
      "Dataset std: tensor([0.2721, 0.2285, 0.1913])\n",
      "Dataset statistics saved to 'dataset_stats.pth'\n"
     ]
    }
   ],
   "source": [
    "def calculate_dataset_stats(csv_file, img_dir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset = StabilityDataset(csv_file=csv_file, img_dir=img_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=1, num_workers=0, shuffle=False)\n",
    "    \n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print(\"Calculating dataset statistics...\")\n",
    "    for i, images in enumerate(loader):\n",
    "        for j in range(3):\n",
    "            mean[j] += images[:, j, :, :].mean()\n",
    "            std[j] += images[:, j, :, :].std()\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(f\"Processed {i+1} images\")\n",
    "    \n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "# Calculate stats\n",
    "csv_file = './COMP90086_2024_Project_train/train.csv'\n",
    "img_dir = './COMP90086_2024_Project_train/train'\n",
    "mean, std = calculate_dataset_stats(csv_file, img_dir)\n",
    "\n",
    "print(f\"Dataset mean: {mean}\")\n",
    "print(f\"Dataset std: {std}\")\n",
    "\n",
    "# Save the stats\n",
    "torch.save({'mean': mean, 'std': std}, 'dataset_stats.pth')\n",
    "print(\"Dataset statistics saved to 'dataset_stats.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6112f1f-8299-43b4-b653-f2b87909b1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset mean: tensor([0.4677, 0.4412, 0.4065])\n",
      "Loaded dataset std: tensor([0.2721, 0.2285, 0.1913])\n",
      "Splitting dataset into 0.975:0.025 training/test split\n",
      "Training...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 468/468 [00:56<00:00,  8.23it/s, loss=1.2487, acc=40.87%]\n",
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  6.21it/s, loss=1.0824, acc=53.65%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3781, Train Acc: 40.87%\n",
      "Val Loss: 1.1304, Val Acc: 53.65%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 468/468 [00:55<00:00,  8.41it/s, loss=1.0296, acc=55.44%]\n",
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  6.32it/s, loss=1.1128, acc=56.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1010, Train Acc: 55.44%\n",
      "Val Loss: 1.0502, Val Acc: 56.77%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|█████▉    | 280/468 [00:34<00:23,  8.15it/s, loss=1.0431, acc=61.28%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstability_predictor_efficientnetv2_classification_augmented.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 14\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[20], line 64\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, data_loader, criterion, optimizer, device, is_training)\u001b[0m\n\u001b[1;32m     61\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     62\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 64\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     65\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience=5):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, device, is_training=True)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer, device, is_training=False)\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 60)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "            model.load_state_dict(best_model)\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_epoch(model, data_loader, criterion, optimizer, device, is_training=True):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\" if is_training else \"Validating\")\n",
    "\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Load pre-calculated dataset statistics\n",
    "stats = torch.load('dataset_stats.pth')\n",
    "mean, std = stats['mean'], stats['std']\n",
    "print(f\"Loaded dataset mean: {mean}\")\n",
    "print(f\"Loaded dataset std: {std}\")\n",
    "\n",
    "# Create transform with loaded normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean.tolist(), std=std.tolist()),\n",
    "])\n",
    "\n",
    "# Create full dataset with augmentation and correct normalization\n",
    "full_dataset = StabilityDataset(csv_file='./COMP90086_2024_Project_train/train.csv', \n",
    "                                img_dir='./COMP90086_2024_Project_train/train', \n",
    "                                transform=transform,\n",
    "                                augment=True)  # Enable augmentation\n",
    "\n",
    "# Split dataset into train and validation\n",
    "val_ratio = 0.025\n",
    "dataset_size = len(full_dataset)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "print(f'Splitting dataset into {(1 - val_ratio)}:{val_ratio} training/test split')\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "model = StabilityPredictor(num_classes=6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "print('Training...')\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=5)\n",
    "\n",
    "torch.save(model.state_dict(), 'stability_predictor_efficientnetv2_classification_augmented.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabe0889-5940-4e36-b3a2-2f4093d48379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, ids in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy() + 1)  # Add 1 to convert back to 1-6 range\n",
    "            image_ids.extend(ids.numpy())  # Convert tensor to numpy array\n",
    "\n",
    "    return predictions, image_ids\n",
    "\n",
    "def main():\n",
    "    # Set up device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Define transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load the unlabeled dataset\n",
    "    test_dataset = StabilityDataset(csv_file='./COMP90086_2024_Project_test/test.csv', \n",
    "                                    img_dir='./COMP90086_2024_Project_test/test', \n",
    "                                    transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Load the trained model\n",
    "    model = StabilityPredictor(num_classes=6)\n",
    "    model.load_state_dict(torch.load('stability_predictor_efficientnetv2_classification_augmented.pth'))\n",
    "    model.to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions, image_ids = predict(model, test_loader, device)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    with open('predictions.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['id', 'labels'])\n",
    "        for img_id, pred in zip(image_ids, predictions):\n",
    "            writer.writerow([int(img_id) + 1, int(pred)])  # Ensure both are integers\n",
    "\n",
    "    print(\"Predictions saved to predictions.csv\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172b1b6a-895d-4a69-a839-762b02e2dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset mean: tensor([0.4677, 0.4412, 0.4065])\n",
      "Loaded dataset std: tensor([0.2721, 0.2285, 0.1913])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 228\u001b[0m\n\u001b[1;32m    225\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m random_split(full_dataset, [train_size, val_size])\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Create balanced sampler for training data\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m train_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_balanced_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Create data loaders\u001b[39;00m\n\u001b[1;32m    231\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mtrain_sampler, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 98\u001b[0m, in \u001b[0;36mcreate_balanced_sampler\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_balanced_sampler\u001b[39m(dataset):\n\u001b[0;32m---> 98\u001b[0m     targets \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstability_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m _, item \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     99\u001b[0m     class_sample_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([(torch\u001b[38;5;241m.\u001b[39mtensor(targets) \u001b[38;5;241m==\u001b[39m t)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39munique(torch\u001b[38;5;241m.\u001b[39mtensor(targets), \u001b[38;5;28msorted\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m    100\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m class_sample_count\u001b[38;5;241m.\u001b[39mfloat()\n",
      "Cell \u001b[0;32mIn[11], line 98\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_balanced_sampler\u001b[39m(dataset):\n\u001b[0;32m---> 98\u001b[0m     targets \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstability_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m _, item \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m     99\u001b[0m     class_sample_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([(torch\u001b[38;5;241m.\u001b[39mtensor(targets) \u001b[38;5;241m==\u001b[39m t)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39munique(torch\u001b[38;5;241m.\u001b[39mtensor(targets), \u001b[38;5;28msorted\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m    100\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m class_sample_count\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py:356\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mEnhancedStabilityDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     31\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstability_data\u001b[38;5;241m.\u001b[39miloc[original_idx]\n\u001b[0;32m---> 32\u001b[0m img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     33\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, img_name)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(img_path):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_id'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28dac5b9-c8cd-4621-82e1-170afee2da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StabilityDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, augment=False):\n",
    "        self.stability_data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "        # Create mappings for categorical variables\n",
    "        self.shapeset_map = {s: i for i, s in enumerate(self.stability_data['shapeset'].unique())}\n",
    "        self.type_map = {t: i for i, t in enumerate(self.stability_data['type'].unique())}\n",
    "        self.instability_type_map = {it: i for i, it in enumerate(self.stability_data['instability_type'].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stability_data) * (2 if self.augment else 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx // 2 if self.augment else idx\n",
    "        flip = self.augment and idx % 2 == 1\n",
    "\n",
    "        img_name = str(self.stability_data.iloc[original_idx, 0])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(self.img_dir, f\"{img_name}.jpg\")\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        row = self.stability_data.iloc[original_idx]\n",
    "        stability_class = int(row['total_height']) - 1\n",
    "\n",
    "        # Get additional features\n",
    "        shapeset = self.shapeset_map[row['shapeset']]\n",
    "        type_ = self.type_map[row['type']]\n",
    "        instability_type = self.instability_type_map[row['instability_type']]\n",
    "        cam_angle = row['cam_angle']\n",
    "\n",
    "        if flip:\n",
    "            image = image.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(stability_class, dtype=torch.long), torch.tensor([shapeset, type_, instability_type, cam_angle], dtype=torch.float)\n",
    "\n",
    "class MultiTaskStabilityPredictor(nn.Module):\n",
    "    def __init__(self, num_stability_classes=6, num_shapeset_classes=None, num_type_classes=None, num_instability_type_classes=None):\n",
    "        super(MultiTaskStabilityPredictor, self).__init__()\n",
    "        weights = EfficientNet_V2_S_Weights.DEFAULT\n",
    "        self.efficientnet = models.efficientnet_v2_s(weights=weights)\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        \n",
    "        # Remove the original classifier\n",
    "        self.efficientnet = nn.Sequential(*list(self.efficientnet.children())[:-1])\n",
    "        \n",
    "        # Add new classifiers for each task\n",
    "        self.stability_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(num_ftrs, num_stability_classes)\n",
    "        )\n",
    "        self.shapeset_classifier = nn.Linear(num_ftrs, num_shapeset_classes)\n",
    "        self.type_classifier = nn.Linear(num_ftrs, num_type_classes)\n",
    "        self.instability_type_classifier = nn.Linear(num_ftrs, num_instability_type_classes)\n",
    "        self.cam_angle_regressor = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.efficientnet(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        \n",
    "        stability = self.stability_classifier(features)\n",
    "        shapeset = self.shapeset_classifier(features)\n",
    "        type_ = self.type_classifier(features)\n",
    "        instability_type = self.instability_type_classifier(features)\n",
    "        cam_angle = self.cam_angle_regressor(features)\n",
    "        \n",
    "        return stability, shapeset, type_, instability_type, cam_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "995b4e3c-c7bf-4a3b-93d6-ef999c983e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset mean: tensor([0.4677, 0.4412, 0.4065])\n",
      "Loaded dataset std: tensor([0.2721, 0.2285, 0.1913])\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.39it/s, loss=0.5347, acc=80.91%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 17.28it/s, loss=0.6160, acc=90.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8008, Train Acc: 80.91%\n",
      "Val Loss: 0.5171, Val Acc: 90.04%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.38it/s, loss=0.4180, acc=92.17%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 18.15it/s, loss=0.3278, acc=94.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4681, Train Acc: 92.17%\n",
      "Val Loss: 0.3745, Val Acc: 94.60%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.32it/s, loss=0.3535, acc=94.70%]\n",
      "Validating: 100%|██████████| 48/48 [00:03<00:00, 14.12it/s, loss=0.3821, acc=95.51%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3795, Train Acc: 94.70%\n",
      "Val Loss: 0.3447, Val Acc: 95.51%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.42it/s, loss=0.2570, acc=96.35%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 17.05it/s, loss=0.3305, acc=95.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3240, Train Acc: 96.35%\n",
      "Val Loss: 0.3286, Val Acc: 95.38%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:54<00:00,  7.95it/s, loss=0.2372, acc=96.75%]\n",
      "Validating: 100%|██████████| 48/48 [00:03<00:00, 15.81it/s, loss=0.3189, acc=95.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3044, Train Acc: 96.75%\n",
      "Val Loss: 0.3224, Val Acc: 95.77%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.40it/s, loss=0.2661, acc=96.95%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 17.13it/s, loss=0.3119, acc=94.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2959, Train Acc: 96.95%\n",
      "Val Loss: 0.3782, Val Acc: 94.86%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.41it/s, loss=0.2298, acc=97.30%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 17.33it/s, loss=0.2596, acc=94.27%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2693, Train Acc: 97.30%\n",
      "Val Loss: 0.4154, Val Acc: 94.27%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.35it/s, loss=0.2484, acc=97.64%]\n",
      "Validating: 100%|██████████| 48/48 [00:03<00:00, 15.06it/s, loss=0.2831, acc=96.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2620, Train Acc: 97.64%\n",
      "Val Loss: 0.2956, Val Acc: 96.42%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.45it/s, loss=0.1958, acc=98.28%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 18.46it/s, loss=0.2442, acc=97.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2346, Train Acc: 98.28%\n",
      "Val Loss: 0.2753, Val Acc: 97.33%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:50<00:00,  8.59it/s, loss=0.1868, acc=98.71%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 18.56it/s, loss=0.2457, acc=97.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2112, Train Acc: 98.71%\n",
      "Val Loss: 0.2782, Val Acc: 97.20%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:50<00:00,  8.48it/s, loss=0.2298, acc=98.19%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 18.74it/s, loss=0.2964, acc=97.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2275, Train Acc: 98.19%\n",
      "Val Loss: 0.2756, Val Acc: 97.01%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:50<00:00,  8.49it/s, loss=0.1812, acc=98.66%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 18.67it/s, loss=0.1948, acc=97.66%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2023, Train Acc: 98.66%\n",
      "Val Loss: 0.2702, Val Acc: 97.66%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:50<00:00,  8.52it/s, loss=0.1818, acc=98.81%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 17.07it/s, loss=0.3098, acc=95.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1980, Train Acc: 98.81%\n",
      "Val Loss: 0.3051, Val Acc: 95.83%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:50<00:00,  8.49it/s, loss=0.1740, acc=98.53%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 19.12it/s, loss=0.2450, acc=96.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2008, Train Acc: 98.53%\n",
      "Val Loss: 0.3169, Val Acc: 96.42%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 432/432 [00:51<00:00,  8.44it/s, loss=0.1242, acc=98.92%]\n",
      "Validating: 100%|██████████| 48/48 [00:02<00:00, 18.78it/s, loss=0.2224, acc=97.27%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1803, Train Acc: 98.92%\n",
      "Val Loss: 0.2726, Val Acc: 97.27%\n",
      "Learning Rate: 0.001000\n",
      "------------------------------------------------------------\n",
      "Early stopping triggered after 15 epochs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, random_split\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import EfficientNet_V2_S_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience=5):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, device, is_training=True)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer, device, is_training=False)\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 60)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "            model.load_state_dict(best_model)\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_epoch(model, data_loader, criterion, optimizer, device, is_training=True):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\" if is_training else \"Validating\")\n",
    "\n",
    "    for inputs, stability_labels, aux_labels in progress_bar:\n",
    "        inputs, stability_labels, aux_labels = inputs.to(device), stability_labels.to(device), aux_labels.to(device)\n",
    "        \n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        stability, shapeset, type_, instability_type, cam_angle = model(inputs)\n",
    "        \n",
    "        # Calculate losses for each task\n",
    "        stability_loss = criterion['stability'](stability, stability_labels)\n",
    "        shapeset_loss = criterion['shapeset'](shapeset, aux_labels[:, 0].long())\n",
    "        type_loss = criterion['type'](type_, aux_labels[:, 1].long())\n",
    "        instability_type_loss = criterion['instability_type'](instability_type, aux_labels[:, 2].long())\n",
    "        cam_angle_loss = criterion['cam_angle'](cam_angle.squeeze(), aux_labels[:, 3])\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = stability_loss + 0.2 * (shapeset_loss + type_loss + instability_type_loss + cam_angle_loss)\n",
    "        \n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = stability.max(1)\n",
    "        total += stability_labels.size(0)\n",
    "        correct += predicted.eq(stability_labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def main():\n",
    "    # Load pre-calculated dataset statistics\n",
    "    stats = torch.load('dataset_stats.pth')\n",
    "    mean, std = stats['mean'], stats['std']\n",
    "    print(f\"Loaded dataset mean: {mean}\")\n",
    "    print(f\"Loaded dataset std: {std}\")\n",
    "\n",
    "    # Create transform with loaded normalization\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean.tolist(), std=std.tolist()),\n",
    "    ])\n",
    "\n",
    "    # Create full dataset with augmentation and correct normalization\n",
    "    full_dataset = StabilityDataset(\n",
    "        csv_file='./COMP90086_2024_Project_train/train.csv', \n",
    "        img_dir='./COMP90086_2024_Project_train/train', \n",
    "        transform=transform,\n",
    "        augment=True\n",
    "    )\n",
    "\n",
    "    # Split dataset into train and validation\n",
    "    dataset_size = len(full_dataset)\n",
    "    val_ratio = 0.05\n",
    "    print(f'Splitting into {(1-val_ratio)} : {val_ratio} test/train split')\n",
    "    val_size = int(val_ratio * dataset_size)\n",
    "    train_size = dataset_size - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = MultiTaskStabilityPredictor(\n",
    "        num_stability_classes=6, \n",
    "        num_shapeset_classes=len(full_dataset.shapeset_map),\n",
    "        num_type_classes=len(full_dataset.type_map),\n",
    "        num_instability_type_classes=len(full_dataset.instability_type_map)\n",
    "    )\n",
    "    \n",
    "    criterion = {\n",
    "        'stability': nn.CrossEntropyLoss(),\n",
    "        'shapeset': nn.CrossEntropyLoss(),\n",
    "        'type': nn.CrossEntropyLoss(),\n",
    "        'instability_type': nn.CrossEntropyLoss(),\n",
    "        'cam_angle': nn.MSELoss()\n",
    "    }\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=3)\n",
    "\n",
    "    torch.save(model.state_dict(), 'multitask_stability_predictor.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "992f5485-89ca-4ea2-b908-c3e5d7e76012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 60/60 [00:02<00:00, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to test_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.test_data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.test_data.iloc[idx, 0])  # Assuming the image ID is in the first column\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(self.img_dir, f\"{img_name}.jpg\")\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_name\n",
    "\n",
    "def predict_test_set(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, img_names in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            inputs = inputs.to(device)\n",
    "            stability, _, _, _, _ = model(inputs)\n",
    "            _, predicted = stability.max(1)\n",
    "            \n",
    "            for img_name, pred in zip(img_names, predicted):\n",
    "                predictions.append((img_name, pred.item() + 1))  # Add 1 to convert back to 1-6 range\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def save_predictions_to_csv(predictions, output_file):\n",
    "    df = pd.DataFrame(predictions, columns=['id', 'stable_height'])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to {output_file}\")\n",
    "\n",
    "def predict_and_save():\n",
    "    # Load the trained model\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create a temporary dataset to get the number of classes\n",
    "    temp_dataset = StabilityDataset(\n",
    "        csv_file='./COMP90086_2024_Project_train/train.csv',\n",
    "        img_dir='./COMP90086_2024_Project_train/train',\n",
    "        transform=None,\n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    model = MultiTaskStabilityPredictor(\n",
    "        num_stability_classes=6, \n",
    "        num_shapeset_classes=len(temp_dataset.shapeset_map),\n",
    "        num_type_classes=len(temp_dataset.type_map),\n",
    "        num_instability_type_classes=len(temp_dataset.instability_type_map)\n",
    "    )\n",
    "    model.load_state_dict(torch.load('multitask_stability_predictor.pth'))\n",
    "    model.to(device)\n",
    "\n",
    "    # Load pre-calculated dataset statistics\n",
    "    stats = torch.load('dataset_stats.pth')\n",
    "    mean, std = stats['mean'], stats['std']\n",
    "\n",
    "    # Create transform for test set\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean.tolist(), std=std.tolist()),\n",
    "    ])\n",
    "\n",
    "    # Create test dataset and dataloader\n",
    "    test_dataset = TestDataset(\n",
    "        csv_file='./COMP90086_2024_Project_test/test.csv',\n",
    "        img_dir='./COMP90086_2024_Project_test/test',\n",
    "        transform=test_transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Predict on test set\n",
    "    predictions = predict_test_set(model, test_loader, device)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    save_predictions_to_csv(predictions, 'test_predictions.csv')\n",
    "\n",
    "\n",
    "predict_and_save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
