{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6ed051-4aaf-466a-9884-223ec430dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import EfficientNet_V2_S_Weights\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb6d8fb-64ea-4fc0-b14d-3758ae3c5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StabilityDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, augment=False):\n",
    "        self.stability_data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stability_data) * (2 if self.augment else 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx // 2 if self.augment else idx\n",
    "        flip = self.augment and idx % 2 == 1\n",
    "\n",
    "        img_name = str(self.stability_data.iloc[original_idx, 0])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(self.img_dir, f\"{img_name}.jpg\")\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        stability_height = self.stability_data.iloc[original_idx, -1]\n",
    "        stability_class = int(stability_height) - 1\n",
    "\n",
    "        if flip:\n",
    "            image = image.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(stability_class, dtype=torch.long)\n",
    "\n",
    "class StabilityPredictor(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(StabilityPredictor, self).__init__()\n",
    "        weights = EfficientNet_V2_S_Weights.DEFAULT\n",
    "        self.efficientnet = models.efficientnet_v2_s(weights=weights)\n",
    "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91326bf-e9ee-46d3-91f6-3ff25a8c433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience=5):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, device, is_training=True)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer, device, is_training=False)\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 60)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "            model.load_state_dict(best_model)\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_epoch(model, data_loader, criterion, optimizer, device, is_training=True):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\" if is_training else \"Validating\")\n",
    "\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Load pre-calculated dataset statistics\n",
    "stats = torch.load('dataset_stats.pth')\n",
    "mean, std = stats['mean'], stats['std']\n",
    "print(f\"Loaded dataset mean: {mean}\")\n",
    "print(f\"Loaded dataset std: {std}\")\n",
    "\n",
    "# Create transform with loaded normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean.tolist(), std=std.tolist()),\n",
    "])\n",
    "\n",
    "# Create full dataset with augmentation and correct normalization\n",
    "full_dataset = StabilityDataset(csv_file='./COMP90086_2024_Project_train/train.csv', \n",
    "                                img_dir='./COMP90086_2024_Project_train/train', \n",
    "                                transform=transform,\n",
    "                                augment=True)  # Enable augmentation\n",
    "\n",
    "# Split dataset into train and validation\n",
    "val_ratio = 0.025\n",
    "dataset_size = len(full_dataset)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "print(f'Splitting dataset into {(1 - val_ratio)}:{val_ratio} training/test split')\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "model = StabilityPredictor(num_classes=6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "print('Training...')\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=5)\n",
    "\n",
    "torch.save(model.state_dict(), 'stability_predictor_efficientnetv2_classification_augmented.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c224dd3-57ae-4064-a010-88be189925f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, ids in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy() + 1)  # Add 1 to convert back to 1-6 range\n",
    "            image_ids.extend(ids.numpy())  # Convert tensor to numpy array\n",
    "\n",
    "    return predictions, image_ids\n",
    "    \n",
    "# Set up device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the unlabeled dataset\n",
    "test_dataset = StabilityDataset(csv_file='./COMP90086_2024_Project_test/test.csv', \n",
    "                                img_dir='./COMP90086_2024_Project_test/test', \n",
    "                                transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the trained model\n",
    "model = StabilityPredictor(num_classes=6)\n",
    "model.load_state_dict(torch.load('stability_predictor_efficientnetv2_classification_augmented.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# Make predictions\n",
    "predictions, image_ids = predict(model, test_loader, device)\n",
    "\n",
    "# Save predictions to CSV\n",
    "with open('predictions.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['id', 'labels'])\n",
    "    for img_id, pred in zip(image_ids, predictions):\n",
    "        writer.writerow([int(img_id) + 1, int(pred)])  # Ensure both are integers\n",
    "\n",
    "print(\"Predictions saved to predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
