{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved to: split_train.csv\n",
      "Validation set saved to: split_val.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def split_csv(file_path, train_ratio=0.9, random_state=43):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Split the data into train and validation sets\n",
    "    train_data, val_data = train_test_split(df, test_size=(1-train_ratio), random_state=random_state)\n",
    "    \n",
    "    # Generate new file names\n",
    "    base_name = file_path.rsplit('.', 1)[0]\n",
    "    train_file = f\"split_train.csv\"\n",
    "    val_file = f\"split_val.csv\"\n",
    "    \n",
    "    # Save the split datasets\n",
    "    train_data.to_csv(train_file, index=False)\n",
    "    val_data.to_csv(val_file, index=False)\n",
    "    \n",
    "    print(f\"Training set saved to: {train_file}\")\n",
    "    print(f\"Validation set saved to: {val_file}\")\n",
    "    \n",
    "    return train_file, val_file\n",
    "\n",
    "# Usage example\n",
    "file_path = \"./COMP90086_2024_Project_train/train.csv\"\n",
    "train_file, val_file = split_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/7680 [00:00<?, ?it/s]/tmp/ipykernel_272164/354567196.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  img_name = str(row[0])\n",
      "Processing images: 100%|██████████| 7680/7680 [01:39<00:00, 77.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image statistics saved to dataset_stats/full_quantized.json\n",
      "Mean: [118.6946178  111.99958266 103.1688242 ]\n",
      "Std: [68.48892217 57.7008792  47.95330727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/6912 [00:00<?, ?it/s]/tmp/ipykernel_272164/354567196.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  img_name = str(row[0])\n",
      "Processing images: 100%|██████████| 6912/6912 [00:58<00:00, 119.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image statistics saved to dataset_stats/split_quantized.json\n",
      "Mean: [118.8203705  112.10561837 103.24939132]\n",
      "Std: [68.55053308 57.7906873  48.00791136]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/7680 [00:00<?, ?it/s]/tmp/ipykernel_272164/354567196.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  img_name = str(row[0])\n",
      "Processing images: 100%|██████████| 7680/7680 [00:42<00:00, 179.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image statistics saved to dataset_stats/full.json\n",
      "Mean: [119.21526968 112.51073973 103.68285506]\n",
      "Std: [69.10808986 58.16075209 48.56616013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/6912 [00:00<?, ?it/s]/tmp/ipykernel_272164/354567196.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  img_name = str(row[0])\n",
      "Processing images: 100%|██████████| 6912/6912 [00:47<00:00, 145.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image statistics saved to dataset_stats/split.json\n",
      "Mean: [119.34120849 112.61692033 103.76272418]\n",
      "Std: [69.17001857 58.25038132 48.62095091]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def calculate_image_stats(csv_file, csv_name, img_dir, use_quantized):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Initialize variables for mean and std calculation\n",
    "    sum_means = np.zeros(3)\n",
    "    sum_stds = np.zeros(3)\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through all images\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing images\"):\n",
    "        img_name = str(row[0])\n",
    "        if use_quantized:\n",
    "            img_path = os.path.join(img_dir, f\"quantized/{img_name}_quantized.jpg\")\n",
    "        else:\n",
    "            img_path = os.path.join(img_dir, f\"{img_name}_original.jpg\")\n",
    "        \n",
    "        # Skip augmented images\n",
    "        if \"_flipped\" in img_path or \"_zoomed\" in img_path:\n",
    "            continue\n",
    "\n",
    "        # Read and process the image\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not read image {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Calculate mean and std for each channel\n",
    "        means = np.mean(image, axis=(0, 1))\n",
    "        stds = np.std(image, axis=(0, 1))\n",
    "        \n",
    "        sum_means += means\n",
    "        sum_stds += stds\n",
    "        count += 1\n",
    "\n",
    "    # Calculate final mean and std\n",
    "    final_mean = sum_means / count\n",
    "    final_std = sum_stds / count\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": final_mean.tolist(),\n",
    "        \"std\": final_std.tolist()\n",
    "    }\n",
    "\n",
    "    quant = \"_quantized\" if use_quantized else \"\"\n",
    "    output_file = f\"dataset_stats/{csv_name}{quant}.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(stats, f, indent=4)\n",
    "\n",
    "    print(f\"Image statistics saved to {output_file}\")\n",
    "    print(f\"Mean: {final_mean}\")\n",
    "    print(f\"Std: {final_std}\")\n",
    "\n",
    "img_dir = './preprocessed_images/train'\n",
    "main_train = './COMP90086_2024_Project_train/train.csv'\n",
    "split_train = 'split_train.csv'\n",
    "\n",
    "for quant in [True, False]:\n",
    "    calculate_image_stats(main_train, \"full\", img_dir, quant)\n",
    "    calculate_image_stats(split_train, \"split\", img_dir, quant)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
